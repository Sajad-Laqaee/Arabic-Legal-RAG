# ğŸ›ï¸ Arabic Legal RAG Pipeline 
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![FAISS](https://img.shields.io/badge/FAISS-Latest-purple)](https://github.com/facebookresearch/faiss)
[![CrossEncoder](https://img.shields.io/badge/CrossEncoder-Latest-orange)](https://www.sbert.net/examples/applications/re-ranking/README.html)
[![Ollama](https://img.shields.io/badge/Ollama-LLM-lightblue)](https://ollama.ai/)

> A highâ€‘precision Retrievalâ€‘Augmented Generation (RAG) system for Arabic legal texts, designed for correctness over confidence.


---

## âœ¨ Overview

This repository contains an **endâ€‘toâ€‘end Arabic Legal RAG pipeline** built for Omani laws and royal decrees. It combines:

* Contextâ€‘aware legal chunking
* Dense vector retrieval (FAISS)
* Neural reâ€‘ranking (Crossâ€‘Encoder)
* A strictly controlled LLM prompt for grounded answers

The system is opinionated by design: **it refuses to answer when the evidence is insufficient**.

---

## ğŸ§  Architecture at a Glance

```
JSON Laws
   â†“
Legal Chunking (Articles + Text)
   â†“
Arabic Normalization
   â†“
Sentenceâ€‘Transformer Embeddings
   â†“
FAISS (IVF + Cosine Similarity)
   â†“
Crossâ€‘Encoder Reâ€‘Ranking
   â†“
LLM with Evidenceâ€‘Bound Prompt
   â†“
Cited Arabic Legal Answer
```

---

## ğŸ“‚ Dataset Assumptions

The pipeline expects a JSON file containing a **list of legal documents (laws / decrees)**. While the real dataset may include additional metadata, only a subset of fields is required for the RAG logic.

### ğŸ“„ Minimal Example (Simplified)

```json
{
  "canonical_link": "https://qanoon.om/p/2025/rd2025100/",
  "text": "Ù†Ø­Ù† Ù‡ÙŠØ«Ù… Ø¨Ù† Ø·Ø§Ø±Ù‚ Ø³Ù„Ø·Ø§Ù† Ø¹Ù…Ø§Ù† ...",
  "issue_at": "ØµØ¯Ø± ÙÙŠ: Ù¢Ù¨ Ù…Ù† Ø¬Ù…Ø§Ø¯Ù‰ Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø³Ù†Ø© Ù¡Ù¤Ù¤Ù§ Ù‡Ù€",
  "publication": "Ù†Ø´Ø± ÙÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ø±ÙŠØ¯Ø© Ø§Ù„Ø±Ø³Ù…ÙŠØ© Ø±Ù‚Ù… (Ù¡Ù¦Ù¢Ù£)...",
  "articles": [
    {
      "title": "Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰",
      "text": "Ø§Ù„ØªØµØ¯ÙŠÙ‚ Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªÙØ§Ù‚ÙŠØ© Ø§Ù„Ù…Ø´Ø§Ø± Ø¥Ù„ÙŠÙ‡Ø§..."
    }
  ]
}
```

### ğŸ”‘ Field Usage

* **`canonical_link`** â†’ Extracts decree year and number for legal context
* **`text`** â†’ Source for preamble extraction and raw text chunking
* **`articles[].title`** â†’ Determines article numbering
* **`articles[].text`** â†’ Clause-level splitting and article chunks
* **`issue_at`, `publication`** â†’ Context enrichment for higher retrieval precision

Additional fields (e.g. source URLs, signatures, approval dates) may exist in the dataset but are not required by the current pipeline.

---

## ğŸ§© Chunking Strategy (Core Design)

This project intentionally uses **two parallel chunking paths** to balance recall and precision.

### 1ï¸âƒ£ Articleâ€‘Based Chunks (Primary)

Highâ€‘signal chunks built around legal semantics:

* Decree metadata (year, number, publication)
* Extracted short preamble (Ø¯ÙŠØ¨Ø§Ø¬Ø© Ù…Ø®ØªØµØ±Ø©)
* Article text
* Clauseâ€‘level splitting when applicable
* Line overlap to preserve continuity

These chunks are the backbone of accurate legal answers.

### 2ï¸âƒ£ Textâ€‘Based Chunks (Supplementary)

The raw `text` field of each law is also chunked:

* Fixed number of lines per chunk
* Configurable overlap

This improves recall for:

* Agreements
* Introductions
* Nonâ€‘article provisions

---

## ğŸ“ Arabic Normalization

Before embedding, both documents and queries undergo lightweight normalization:

* Remove tatweel (Ù€)
* Normalize Alef variants â†’ Ø§
* Normalize Ù‰ â†’ ÙŠ, Ø© â†’ Ù‡
* Collapse extra whitespace

This keeps the vector space stable without harming semantics.

---

## ğŸ“ Embeddings & Vector Search

### ğŸ”¹ Embedding Model

* **Model:** `Omartificial-Intelligence-Space/Arabic-Triplet-Matryoshka-V2`
* Dense Arabic semantic embeddings

### ğŸ”¹ FAISS Index

* Type: `IndexIVFFlat`
* Metric: Inner Product (cosine similarity after normalization)
* Trained on a subset of chunks

Optimized for **recall**, not final ranking.

---

## ğŸ” Retrieval & Reâ€‘Ranking

### Step 1: Biâ€‘Encoder Retrieval

* Query â†’ embedding
* FAISS retrieves topâ€‘K candidate chunks

Fast, scalable, and intentionally noisy.

### Step 2: Crossâ€‘Encoder Reâ€‘Ranking

* **Model:** `Omartificial-Intelligence-Space/ARA-Reranker-V1`
* Scores each (query, chunk) pair jointly

### ğŸ”¢ Hybrid Ranking Formula

```
FinalRank = Î± Â· CrossEncoderRank + (1 âˆ’ Î±) Â· FAISSRank
```

* `Î± â†’ 1`: trust semantic relevance
* `Î± â†’ 0`: trust vector similarity

This avoids brittle ranking behavior.

---

## ğŸ¤– Answer Generation (LLM)

Top reâ€‘ranked chunks are passed to an LLM with a **strict Arabic legal prompt** enforcing:

* Evidenceâ€‘only answers
* No hallucination
* Explicit verification of relevance
* Mandatory source citation

If no chunk answers the question, the system **must reply**:

> Ù…ØªØ£Ø³ÙØŒ Ù„Ù… Ø£Ø¬Ø¯ Ø£ÙŠ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø§Ø³Ø¨Ø©.

This is a feature, not a failure.

---

## ğŸ“¤ Output Characteristics

Final answers are:

* Formal Arabic
* Concise but complete
* Fully grounded in retrieved text
* Accompanied by clear sources (URL, rank, relevance)

Correctness is prioritized over fluency.

---




